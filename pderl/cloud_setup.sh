#!/bin/bash

# PDERLäº‘å¹³å°å¿«é€Ÿéƒ¨ç½²è„šæœ¬
# åœ¨Linuxäº‘å¹³å°ä¸Šä¸€é”®è®¾ç½®ç¯å¢ƒå’Œå¼€å§‹è®­ç»ƒ

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

echo "========================================"
echo "PDERL äº‘å¹³å°å¿«é€Ÿéƒ¨ç½²è„šæœ¬"
echo "========================================"
echo

# æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯
echo "ğŸ–¥ï¸ ç³»ç»Ÿä¿¡æ¯:"
echo "æ“ä½œç³»ç»Ÿ: $(uname -s)"
echo "å†…æ ¸ç‰ˆæœ¬: $(uname -r)"
echo "æ¶æ„: $(uname -m)"
echo

# æ£€æŸ¥NVIDIA GPU
echo "ğŸ® æ£€æŸ¥GPUä¿¡æ¯..."
if command -v nvidia-smi &> /dev/null; then
    nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits
    echo "âœ… NVIDIA GPUæ£€æµ‹æˆåŠŸ"
else
    echo "âš ï¸ æœªæ£€æµ‹åˆ°NVIDIA GPUæˆ–nvidia-smiå‘½ä»¤"
fi
echo

# æ£€æŸ¥conda
echo "ğŸ æ£€æŸ¥Condaç¯å¢ƒ..."
if command -v conda &> /dev/null; then
    echo "âœ… Condaå·²å®‰è£…: $(conda --version)"
else
    echo "âŒ Condaæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Minicondaæˆ–Anaconda"
    echo "ä¸‹è½½åœ°å€: https://docs.conda.io/en/latest/miniconda.html"
    exit 1
fi
echo

# åˆ›å»ºcondaç¯å¢ƒ
echo "ğŸ”§ åˆ›å»ºcondaç¯å¢ƒ..."
if conda env list | grep -q "erl_env"; then
    echo "âš ï¸ erl_envç¯å¢ƒå·²å­˜åœ¨"
    read -p "æ˜¯å¦åˆ é™¤å¹¶é‡æ–°åˆ›å»º? (y/n): " recreate
    if [[ "$recreate" =~ ^[Yy]$ ]]; then
        conda env remove -n erl_env -y
        echo "ğŸ—‘ï¸ å·²åˆ é™¤æ—§ç¯å¢ƒ"
    else
        echo "ğŸ“¦ ä½¿ç”¨ç°æœ‰ç¯å¢ƒ"
    fi
fi

if ! conda env list | grep -q "erl_env"; then
    echo "ğŸ“¦ åˆ›å»ºæ–°çš„erl_envç¯å¢ƒ..."
    conda create -n erl_env python=3.8 -y
    echo "âœ… ç¯å¢ƒåˆ›å»ºæˆåŠŸ"
fi

# æ¿€æ´»ç¯å¢ƒ
echo "ğŸ”„ æ¿€æ´»ç¯å¢ƒ..."
source $(conda info --base)/etc/profile.d/conda.sh
conda activate erl_env
echo "âœ… ç¯å¢ƒå·²æ¿€æ´»: $CONDA_DEFAULT_ENV"
echo

# å®‰è£…PyTorch (CUDAç‰ˆæœ¬)
echo "ğŸ”¥ å®‰è£…PyTorch (CUDAç‰ˆæœ¬)..."
echo "è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´..."
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y
echo "âœ… PyTorchå®‰è£…å®Œæˆ"
echo

# éªŒè¯CUDA
echo "ğŸ§ª éªŒè¯CUDAæ”¯æŒ..."
python -c "import torch; print('CUDA available:', torch.cuda.is_available())"
python -c "import torch; print('GPU count:', torch.cuda.device_count())"
if python -c "import torch; print(torch.cuda.is_available())" | grep -q "True"; then
    python -c "import torch; print('GPU name:', torch.cuda.get_device_name(0))"
    echo "âœ… CUDAæ”¯æŒéªŒè¯æˆåŠŸ"
else
    echo "âš ï¸ CUDAæ”¯æŒéªŒè¯å¤±è´¥ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ"
fi
echo

# å®‰è£…å…¶ä»–ä¾èµ–
echo "ğŸ“¦ å®‰è£…é¡¹ç›®ä¾èµ–..."
if [ -f "requirements.txt" ]; then
    pip install -r requirements.txt
    echo "âœ… ä¾èµ–å®‰è£…å®Œæˆ"
else
    echo "âš ï¸ requirements.txtæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ‰‹åŠ¨å®‰è£…æ ¸å¿ƒä¾èµ–..."
    pip install numpy scipy matplotlib seaborn pandas gym mujoco-py psutil tqdm
fi
echo

# è®¾ç½®MuJoCo (å¦‚æœéœ€è¦)
echo "ğŸ¤– æ£€æŸ¥MuJoCoç¯å¢ƒ..."
if python -c "import mujoco_py" 2>/dev/null; then
    echo "âœ… MuJoCoç¯å¢ƒæ­£å¸¸"
else
    echo "âš ï¸ MuJoCoç¯å¢ƒå¯èƒ½éœ€è¦é¢å¤–é…ç½®"
    echo "å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·å‚è€ƒ: https://github.com/openai/mujoco-py"
fi
echo

# æµ‹è¯•ç¯å¢ƒ
echo "ğŸ§ª æµ‹è¯•è®­ç»ƒç¯å¢ƒ..."
if python -c "import gym; env = gym.make('Walker2d-v2'); print('âœ… Walker2d-v2ç¯å¢ƒæµ‹è¯•æˆåŠŸ')" 2>/dev/null; then
    echo "âœ… è®­ç»ƒç¯å¢ƒæµ‹è¯•é€šè¿‡"
else
    echo "âš ï¸ è®­ç»ƒç¯å¢ƒæµ‹è¯•å¤±è´¥ï¼Œå¯èƒ½éœ€è¦é¢å¤–é…ç½®"
fi
echo

# æ˜¾ç¤ºå¯ç”¨çš„è®­ç»ƒé€‰é¡¹
echo "========================================"
echo "ğŸš€ ç¯å¢ƒè®¾ç½®å®Œæˆï¼å¯ç”¨çš„è®­ç»ƒé€‰é¡¹:"
echo "========================================"
echo
echo "1. äº¤äº’å¼è®­ç»ƒ (æ¨è):"
echo "   ./run_parallel_experiments.sh"
echo
echo "2. GPUä¼˜åŒ–è®­ç»ƒ (16Gæ˜¾å­˜):"
echo "   python parallel_train.py -env Walker2d-v2 -preset gpu_optimized -workers 5"
echo
echo "3. å¿«é€Ÿæµ‹è¯•:"
echo "   python parallel_train.py -env Hopper-v2 -preset quick_test -workers 3"
echo
echo "4. è‡ªå®šä¹‰è®­ç»ƒ:"
echo "   python parallel_train.py -env HalfCheetah-v2 -seeds 1 2 3 4 5 -workers 5"
echo
echo "5. æŸ¥çœ‹æ‰€æœ‰é¢„è®¾:"
echo "   python parallel_train.py --list-presets"
echo
echo "ğŸ“Š ç³»ç»Ÿèµ„æºç›‘æ§:"
echo "   watch -n 1 nvidia-smi  # GPUç›‘æ§"
echo "   htop                   # CPU/å†…å­˜ç›‘æ§"
echo
echo "ğŸ“ è®­ç»ƒç»“æœå°†ä¿å­˜åœ¨: parallel_experiments/"
echo "ğŸ“– è¯¦ç»†æ–‡æ¡£: CLOUD_DEPLOYMENT.md"
echo
echo "ğŸ‰ éƒ¨ç½²å®Œæˆï¼ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒäº†ã€‚"
echo

# è¯¢é—®æ˜¯å¦ç«‹å³å¼€å§‹è®­ç»ƒ
read -p "æ˜¯å¦ç«‹å³å¼€å§‹GPUä¼˜åŒ–è®­ç»ƒ? (y/n): " start_training
if [[ "$start_training" =~ ^[Yy]$ ]]; then
    echo "ğŸš€ å¯åŠ¨GPUä¼˜åŒ–è®­ç»ƒ..."
    echo "y" | python parallel_train.py -env Walker2d-v2 -preset gpu_optimized -workers 5
else
    echo "ğŸ’¡ ç¨åå¯ä»¥æ‰‹åŠ¨è¿è¡Œè®­ç»ƒå‘½ä»¤"
fi

echo "âœ¨ è„šæœ¬æ‰§è¡Œå®Œæˆï¼"