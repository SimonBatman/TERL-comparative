#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PDERL ç»“æœåˆ†æç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å¯è§†åŒ–å·¥å…·è¿›è¡Œè®­ç»ƒç»“æœåˆ†æ
"""

from visualize_results import (
    load_csv_data, 
    print_summary_stats, 
    plot_training_curves,
    plot_selection_stats,
    compare_experiments
)
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt

def analyze_training_progress(result_dir):
    """åˆ†æè®­ç»ƒè¿›å±•"""
    print(f"\n=== åˆ†æè®­ç»ƒè¿›å±•: {Path(result_dir).name} ===")
    
    # åŠ è½½ERLå¾—åˆ†æ•°æ®
    erl_file = Path(result_dir) / 'erl_score.csv'
    if erl_file.exists():
        data = load_csv_data(erl_file)
        
        # è®¡ç®—å­¦ä¹ æ•ˆç‡
        if len(data) > 1:
            total_improvement = data['y'].iloc[-1] - data['y'].iloc[0]
            total_games = data['x'].iloc[-1] - data['x'].iloc[0]
            efficiency = total_improvement / (total_games / 1000)  # æ¯1000æ¸¸æˆçš„æ”¹è¿›
            
            print(f"ğŸ“ˆ å­¦ä¹ æ•ˆç‡: {efficiency:.2f} åˆ†æ•°/åƒæ¸¸æˆ")
            print(f"ğŸ¯ æ€»ä½“æ”¹è¿›: {total_improvement:.2f} åˆ†æ•°")
            
            # æ£€æµ‹æ”¶æ•›
            window_size = min(10, len(data) // 4)
            if window_size > 1:
                rolling_std = data['y'].rolling(window=window_size).std()
                convergence_threshold = data['y'].max() * 0.02  # 2%çš„å˜åŒ–é˜ˆå€¼
                
                converged_points = rolling_std[rolling_std < convergence_threshold]
                if len(converged_points) > 0:
                    convergence_game = data.iloc[converged_points.index[0]]['x']
                    print(f"ğŸ”„ æ”¶æ•›ç‚¹: ç¬¬ {convergence_game:.0f} æ¸¸æˆ")
                else:
                    print("ğŸ”„ å°šæœªæ”¶æ•›")
            
            # åˆ†æè®­ç»ƒé˜¶æ®µ
            analyze_training_phases(data)
    
    return data

def analyze_training_phases(data):
    """åˆ†æè®­ç»ƒçš„ä¸åŒé˜¶æ®µ"""
    print("\nğŸ“Š è®­ç»ƒé˜¶æ®µåˆ†æ:")
    
    total_games = len(data)
    
    # æ—©æœŸé˜¶æ®µ (å‰25%)
    early_end = total_games // 4
    early_data = data.iloc[:early_end]
    early_improvement = early_data['y'].iloc[-1] - early_data['y'].iloc[0] if len(early_data) > 1 else 0
    
    # ä¸­æœŸé˜¶æ®µ (25%-75%)
    mid_start = early_end
    mid_end = total_games * 3 // 4
    mid_data = data.iloc[mid_start:mid_end]
    mid_improvement = mid_data['y'].iloc[-1] - mid_data['y'].iloc[0] if len(mid_data) > 1 else 0
    
    # åæœŸé˜¶æ®µ (å25%)
    late_data = data.iloc[mid_end:]
    late_improvement = late_data['y'].iloc[-1] - late_data['y'].iloc[0] if len(late_data) > 1 else 0
    
    print(f"  ğŸŒ± æ—©æœŸé˜¶æ®µæ”¹è¿›: {early_improvement:.2f}")
    print(f"  ğŸš€ ä¸­æœŸé˜¶æ®µæ”¹è¿›: {mid_improvement:.2f}")
    print(f"  ğŸ¯ åæœŸé˜¶æ®µæ”¹è¿›: {late_improvement:.2f}")
    
    # åˆ¤æ–­è®­ç»ƒçŠ¶æ€
    if late_improvement > 0:
        print("  âœ… è®­ç»ƒä»åœ¨æ”¹è¿›")
    elif abs(late_improvement) < data['y'].std() * 0.1:
        print("  ğŸ”„ è®­ç»ƒå·²æ”¶æ•›")
    else:
        print("  âš ï¸ è®­ç»ƒå¯èƒ½è¿‡æ‹Ÿåˆ")

def compare_rl_vs_evolution(result_dir):
    """æ¯”è¾ƒå¼ºåŒ–å­¦ä¹ å’Œè¿›åŒ–ç®—æ³•çš„è´¡çŒ®"""
    print(f"\n=== RL vs Evolution åˆ†æ: {Path(result_dir).name} ===")
    
    result_path = Path(result_dir)
    
    # åŠ è½½æ•°æ®
    erl_data = load_csv_data(result_path / 'erl_score.csv')
    ddpg_data = load_csv_data(result_path / 'ddpg_score.csv')
    
    if erl_data is not None and ddpg_data is not None:
        # è®¡ç®—ç›¸å…³æ€§ï¼ˆéœ€è¦å¯¹é½æ•°æ®ç‚¹ï¼‰
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„å¯¹é½é€»è¾‘
        erl_final = erl_data['y'].iloc[-1]
        ddpg_final = ddpg_data['y'].iloc[-1]
        
        print(f"ğŸ® ERL æœ€ç»ˆå¾—åˆ†: {erl_final:.2f}")
        print(f"ğŸ¤– DDPG æœ€ç»ˆå¥–åŠ±: {ddpg_final:.2f}")
        
        # åˆ†ææ”¹è¿›è¶‹åŠ¿
        erl_trend = erl_data['y'].iloc[-5:].mean() - erl_data['y'].iloc[:5].mean()
        ddpg_trend = ddpg_data['y'].iloc[-5:].mean() - ddpg_data['y'].iloc[:5].mean()
        
        print(f"ğŸ“ˆ ERL æ”¹è¿›è¶‹åŠ¿: {erl_trend:.2f}")
        print(f"ğŸ“ˆ DDPG æ”¹è¿›è¶‹åŠ¿: {ddpg_trend:.2f}")

def analyze_selection_strategy(result_dir):
    """åˆ†æé€‰æ‹©ç­–ç•¥æ•ˆæœ"""
    print(f"\n=== é€‰æ‹©ç­–ç•¥åˆ†æ: {Path(result_dir).name} ===")
    
    result_path = Path(result_dir)
    
    # åŠ è½½é€‰æ‹©æ•°æ®
    elite_data = load_csv_data(result_path / 'elite_selection.csv')
    selected_data = load_csv_data(result_path / 'selected_selection.csv')
    discarded_data = load_csv_data(result_path / 'discarded_selection.csv')
    
    if all(data is not None for data in [elite_data, selected_data, discarded_data]):
        print(f"ğŸ† å¹³å‡ç²¾è‹±æ¯”ä¾‹: {elite_data['y'].mean():.3f}")
        print(f"âœ… å¹³å‡é€‰æ‹©æ¯”ä¾‹: {selected_data['y'].mean():.3f}")
        print(f"âŒ å¹³å‡ä¸¢å¼ƒæ¯”ä¾‹: {discarded_data['y'].mean():.3f}")
        
        # åˆ†æé€‰æ‹©ç­–ç•¥çš„ç¨³å®šæ€§
        elite_std = elite_data['y'].std()
        print(f"ğŸ“Š ç²¾è‹±é€‰æ‹©ç¨³å®šæ€§ (æ ‡å‡†å·®): {elite_std:.3f}")
        
        if elite_std < 0.05:
            print("  âœ… é€‰æ‹©ç­–ç•¥ç¨³å®š")
        else:
            print("  âš ï¸ é€‰æ‹©ç­–ç•¥æ³¢åŠ¨è¾ƒå¤§")

def generate_performance_report(result_dir):
    """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
    print(f"\n{'='*50}")
    print(f"ğŸ¯ PDERL æ€§èƒ½æŠ¥å‘Š: {Path(result_dir).name}")
    print(f"{'='*50}")
    
    # åŸºç¡€ç»Ÿè®¡
    print_summary_stats(result_dir)
    
    # è¯¦ç»†åˆ†æ
    analyze_training_progress(result_dir)
    compare_rl_vs_evolution(result_dir)
    analyze_selection_strategy(result_dir)
    
    print(f"\n{'='*50}")
    print("ğŸ“‹ æŠ¥å‘Šå®Œæˆ")
    print(f"{'='*50}")

def quick_comparison(result_dirs):
    """å¿«é€Ÿæ¯”è¾ƒå¤šä¸ªå®éªŒ"""
    print("\nğŸ” å®éªŒå¿«é€Ÿæ¯”è¾ƒ")
    print("-" * 80)
    print(f"{'å®éªŒåç§°':<20} {'æœ€é«˜åˆ†æ•°':<12} {'æœ€ç»ˆåˆ†æ•°':<12} {'å¹³å‡åˆ†æ•°':<12} {'æ”¹è¿›å¹…åº¦':<12}")
    print("-" * 80)
    
    for result_dir in result_dirs:
        result_path = Path(result_dir)
        exp_name = result_path.name
        
        erl_file = result_path / 'erl_score.csv'
        if erl_file.exists():
            data = load_csv_data(erl_file)
            if data is not None:
                max_score = data['y'].max()
                final_score = data['y'].iloc[-1]
                avg_score = data['y'].mean()
                improvement = final_score - data['y'].iloc[0] if len(data) > 1 else 0
                
                print(f"{exp_name:<20} {max_score:<12.1f} {final_score:<12.1f} {avg_score:<12.1f} {improvement:<12.1f}")
        else:
            print(f"{exp_name:<20} {'N/A':<12} {'N/A':<12} {'N/A':<12} {'N/A':<12}")
    
    print("-" * 80)

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå„ç§åˆ†æåŠŸèƒ½"""
    # ç¤ºä¾‹ï¼šåˆ†æå•ä¸ªå®éªŒ
    result_dir = 'results/hopper_pderl'
    
    if Path(result_dir).exists():
        print("ğŸš€ å¼€å§‹ PDERL ç»“æœåˆ†æ...")
        
        # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        generate_performance_report(result_dir)
        
        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        plot_training_curves(result_dir, save_plots=True)
        plot_selection_stats(result_dir, save_plots=True)
        
        print("\nâœ… åˆ†æå®Œæˆï¼")
        print("ğŸ“ æŸ¥çœ‹ç”Ÿæˆçš„å›¾ç‰‡æ–‡ä»¶:")
        print(f"   - {result_dir}/training_curves.png")
        print(f"   - {result_dir}/selection_stats.png")
    else:
        print(f"âŒ ç»“æœç›®å½•ä¸å­˜åœ¨: {result_dir}")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒæˆ–æŒ‡å®šæ­£ç¡®çš„ç»“æœç›®å½•")
    
    # ç¤ºä¾‹ï¼šæ¯”è¾ƒå¤šä¸ªå®éªŒï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    results_dir = Path('results')
    if results_dir.exists():
        subdirs = [str(d) for d in results_dir.iterdir() if d.is_dir()]
        if len(subdirs) > 1:
            print("\nğŸ” å‘ç°å¤šä¸ªå®éªŒï¼Œè¿›è¡Œæ¯”è¾ƒåˆ†æ...")
            quick_comparison(subdirs)
            
            print("\nğŸ“Š ç”Ÿæˆæ¯”è¾ƒå›¾è¡¨...")
            compare_experiments(subdirs)

if __name__ == '__main__':
    main()