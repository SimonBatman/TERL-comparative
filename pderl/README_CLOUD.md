# PDERL äº‘å¹³å°å¿«é€Ÿéƒ¨ç½²æŒ‡å—

ğŸš€ **ä¸€é”®éƒ¨ç½²åˆ°äº‘å¹³å°ï¼Œå……åˆ†åˆ©ç”¨GPUèµ„æºè¿›è¡Œå¹¶è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒ**

## å¿«é€Ÿå¼€å§‹

### 1. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/your-username/TERL-comparative.git
cd TERL-comparative/pderl
```

### 2. ä¸€é”®ç¯å¢ƒè®¾ç½®

```bash
# ç»™è„šæœ¬æ‰§è¡Œæƒé™
chmod +x cloud_setup.sh

# è¿è¡Œä¸€é”®éƒ¨ç½²è„šæœ¬
./cloud_setup.sh
```

### 3. å¼€å§‹è®­ç»ƒ

```bash
# äº¤äº’å¼è®­ç»ƒ (æ¨è)
./run_parallel_experiments.sh
# é€‰æ‹©ç¯å¢ƒ -> é€‰æ‹©gpu_optimizedé¢„è®¾ -> å¯ç”¨TensorBoard

# æˆ–ç›´æ¥è¿è¡ŒGPUä¼˜åŒ–è®­ç»ƒ
python parallel_train.py -env Walker2d-v2 -preset gpu_optimized -workers 5
```

### 4. å¯åŠ¨TensorBoardç›‘æ§

```bash
# åœ¨æ–°ç»ˆç«¯ä¸­è¿è¡Œ
tensorboard --logdir=parallel_experiments --port=6006 --host=0.0.0.0
# è®¿é—®: http://your-server-ip:6006
```

## ğŸ“Š é¢„è®¾é…ç½®

| é¢„è®¾ | æè¿° | ç§å­æ•° | TensorBoard | é€‚ç”¨åœºæ™¯ |
|------|------|--------|-------------|----------|
| `gpu_optimized` | GPUä¼˜åŒ– | 5 | âœ… | 16Gæ˜¾å­˜äº‘å¹³å° |
| `quick_test` | å¿«é€Ÿæµ‹è¯• | 3 | âŒ | ç¯å¢ƒéªŒè¯ |
| `standard` | æ ‡å‡†å®éªŒ | 5 | âŒ | å¸¸è§„è®­ç»ƒ |
| `comprehensive` | å…¨é¢å®éªŒ | 10 | âŒ | å®Œæ•´è¯„ä¼° |

## æ”¯æŒçš„ç¯å¢ƒ

- **Hopper-v2** - å•è…¿è·³è·ƒæœºå™¨äºº
- **Walker2d-v2** - åŒè¶³è¡Œèµ°æœºå™¨äºº  
- **HalfCheetah-v2** - åŠçŒè±¹å¥”è·‘
- **Ant-v2** - å››è¶³èš‚èš
- **Swimmer-v2** - æ¸¸æ³³æœºå™¨äºº
- **Reacher-v2** - æœºæ¢°è‡‚åˆ°è¾¾

## æ€§èƒ½å»ºè®®

### GPUå†…å­˜é…ç½®
- **16Gæ˜¾å­˜**: æœ€å¤§5ä¸ªå¹¶å‘
- **24Gæ˜¾å­˜**: æœ€å¤§7-8ä¸ªå¹¶å‘
- **32Gæ˜¾å­˜**: æœ€å¤§10+ä¸ªå¹¶å‘

### é¢„æœŸè®­ç»ƒæ—¶é—´ (16G GPU)
- **Walker2d-v2**: ~2-3å°æ—¶/å®éªŒ
- **HalfCheetah-v2**: ~2-4å°æ—¶/å®éªŒ
- **Ant-v2**: ~3-5å°æ—¶/å®éªŒ

## å¸¸ç”¨å‘½ä»¤

```bash
# æŸ¥çœ‹æ‰€æœ‰é¢„è®¾
python parallel_train.py --list-presets

# è‡ªå®šä¹‰è®­ç»ƒ
python parallel_train.py -env HalfCheetah-v2 -seeds 1 2 3 4 5 -workers 5

# ç›‘æ§GPUä½¿ç”¨
watch -n 1 nvidia-smi

# åˆ†æç»“æœ
python analyze_parallel_results.py

# å¯è§†åŒ–ç»“æœ
python visualize_results.py
```

## é•¿æ—¶é—´è®­ç»ƒ

```bash
# ä½¿ç”¨screenä¿æŒä¼šè¯
screen -S pderl_training
./run_parallel_experiments.sh
# Ctrl+A+D åˆ†ç¦»ä¼šè¯

# é‡æ–°è¿æ¥
screen -r pderl_training
```

## ç»“æœç›®å½•

```
parallel_experiments/
â”œâ”€â”€ experiment_report.json     # å®éªŒæ€»ç»“
â”œâ”€â”€ Walker2d-v2_seed_1/
â”‚   â”œâ”€â”€ training.log           # è®­ç»ƒæ—¥å¿—
â”‚   â””â”€â”€ *.pkl                  # è®­ç»ƒæ¨¡å‹
â””â”€â”€ ...
```

## æ•…éšœæ’é™¤

### CUDAå†…å­˜ä¸è¶³
```bash
# å‡å°‘å¹¶å‘æ•°
python parallel_train.py -env Walker2d-v2 -preset gpu_optimized -workers 3
```

### MuJoCoé—®é¢˜
```bash
# æ£€æŸ¥MuJoCoç¯å¢ƒ
python -c "import mujoco_py; print('MuJoCo OK')"
```

### ç¯å¢ƒæµ‹è¯•
```bash
# æµ‹è¯•å•ä¸ªç¯å¢ƒ
python -c "import gym; env = gym.make('Walker2d-v2'); print('Environment OK')"
```

## æ–‡ä»¶è¯´æ˜

- `cloud_setup.sh` - ä¸€é”®ç¯å¢ƒè®¾ç½®è„šæœ¬
- `run_parallel_experiments.sh` - äº¤äº’å¼è®­ç»ƒè„šæœ¬
- `parallel_train.py` - å¹¶è¡Œè®­ç»ƒä¸»ç¨‹åº
- `requirements.txt` - ä¾èµ–åŒ…åˆ—è¡¨
- `CLOUD_DEPLOYMENT.md` - è¯¦ç»†éƒ¨ç½²æ–‡æ¡£

## æŠ€æœ¯æ”¯æŒ

é‡åˆ°é—®é¢˜è¯·æ£€æŸ¥ï¼š
1. è®­ç»ƒæ—¥å¿—: `parallel_experiments/*/training.log`
2. GPUçŠ¶æ€: `nvidia-smi`
3. ç¯å¢ƒé…ç½®: `conda list`

---

ğŸ¯ **ç›®æ ‡**: åœ¨äº‘å¹³å°ä¸Šé«˜æ•ˆè¿è¡ŒPDERLå¹¶è¡Œè®­ç»ƒï¼Œå……åˆ†åˆ©ç”¨GPUèµ„æº

ğŸ“Š **ç»“æœ**: è·å¾—å¤šä¸ªéšæœºç§å­çš„è®­ç»ƒç»“æœï¼Œæé«˜å®éªŒå¯é æ€§

ğŸ”¬ **åˆ†æ**: ä½¿ç”¨å†…ç½®å·¥å…·åˆ†æå’Œå¯è§†åŒ–è®­ç»ƒç»“æœ