#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PDERL å¹¶è¡Œè®­ç»ƒè„šæœ¬
æ”¯æŒåœ¨åŒä¸€ç¯å¢ƒä¸‹ä½¿ç”¨ä¸åŒéšæœºç§å­è¿›è¡Œå¤šä¸ªå¹¶è¡Œå®éªŒ
"""

import os
import sys
import time
import json
import argparse
import subprocess
import threading
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

try:
    import psutil
except ImportError:
    print("âš ï¸ psutil æœªå®‰è£…ï¼Œæ— æ³•ç›‘æ§ç³»ç»Ÿèµ„æº")
    psutil = None

class ParallelTrainer:
    def __init__(self, base_logdir="parallel_experiments"):
        self.base_logdir = base_logdir
        self.processes = []
        self.results = {}
        self.start_time = None
        
    def create_experiment_config(self, env_name, seeds, base_args=None):
        """åˆ›å»ºå®éªŒé…ç½®"""
        if base_args is None:
            base_args = {}
            
        experiments = []
        for seed in seeds:
            exp_name = f"{env_name}_seed_{seed}"
            logdir = os.path.join(self.base_logdir, exp_name)
            
            config = {
                'name': exp_name,
                'env': env_name,
                'seed': seed,
                'logdir': logdir,
                'args': base_args.copy()
            }
            experiments.append(config)
            
        return experiments
    
    def run_single_experiment(self, config):
        """è¿è¡Œå•ä¸ªå®éªŒ"""
        print(f"ğŸš€ å¯åŠ¨å®éªŒ: {config['name']}")
        
        # æ„å»ºå‘½ä»¤ - ä½¿ç”¨å½“å‰Pythonè§£é‡Šå™¨
        cmd = [
            sys.executable, 'run_pderl.py',
            '-env', config['env'],
            '-seed', str(config['seed']),
            '-logdir', config['logdir']
        ]
        
        # æ·»åŠ é¢å¤–å‚æ•°
        for key, value in config['args'].items():
            if key.startswith('-'):
                cmd.append(key)
                if value is not None:
                    cmd.append(str(value))
            else:
                cmd.extend([f'-{key}', str(value)])
        
        try:
            # åˆ›å»ºæ—¥å¿—ç›®å½•
            os.makedirs(config['logdir'], exist_ok=True)
            
            # å¯åŠ¨è¿›ç¨‹
            log_file = os.path.join(config['logdir'], 'training.log')
            with open(log_file, 'w') as f:
                process = subprocess.Popen(
                    cmd,
                    stdout=f,
                    stderr=subprocess.STDOUT,
                    cwd=os.getcwd(),
                    env=os.environ.copy()  # ç»§æ‰¿å½“å‰ç¯å¢ƒå˜é‡
                )
            
            # è®°å½•è¿›ç¨‹ä¿¡æ¯
            self.processes.append({
                'name': config['name'],
                'process': process,
                'config': config,
                'start_time': time.time(),
                'log_file': log_file
            })
            
            print(f"âœ… å®éªŒ {config['name']} å·²å¯åŠ¨ (PID: {process.pid})")
            
            # ç­‰å¾…è¿›ç¨‹å®Œæˆ
            return_code = process.wait()
            end_time = time.time()
            
            result = {
                'name': config['name'],
                'return_code': return_code,
                'duration': end_time - self.processes[-1]['start_time'],
                'success': return_code == 0
            }
            
            if return_code == 0:
                print(f"âœ… å®éªŒ {config['name']} å®Œæˆ")
            else:
                print(f"âŒ å®éªŒ {config['name']} å¤±è´¥ (è¿”å›ç : {return_code})")
                
            return result
            
        except Exception as e:
            print(f"âŒ å®éªŒ {config['name']} å¯åŠ¨å¤±è´¥: {str(e)}")
            return {
                'name': config['name'],
                'return_code': -1,
                'duration': 0,
                'success': False,
                'error': str(e)
            }
    
    def monitor_system_resources(self):
        """ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        while any(p['process'].poll() is None for p in self.processes if 'process' in p):
            try:
                cpu_percent = psutil.cpu_percent(interval=1)
                memory = psutil.virtual_memory()
                
                print(f"ğŸ“Š ç³»ç»Ÿèµ„æº: CPU {cpu_percent:.1f}%, å†…å­˜ {memory.percent:.1f}%")
                
                # æ£€æŸ¥è¿è¡Œä¸­çš„è¿›ç¨‹
                running_count = sum(1 for p in self.processes if 'process' in p and p['process'].poll() is None)
                print(f"ğŸ”„ è¿è¡Œä¸­çš„å®éªŒ: {running_count}/{len(self.processes)}")
                
                time.sleep(30)  # æ¯30ç§’ç›‘æ§ä¸€æ¬¡
                
            except Exception as e:
                print(f"âš ï¸ èµ„æºç›‘æ§é”™è¯¯: {str(e)}")
                break
    
    def run_parallel_experiments(self, experiments, max_workers=None):
        """å¹¶è¡Œè¿è¡Œå¤šä¸ªå®éªŒ"""
        if max_workers is None:
            max_workers = min(len(experiments), os.cpu_count())
            
        print(f"ğŸ¯ å¼€å§‹å¹¶è¡Œè®­ç»ƒ: {len(experiments)} ä¸ªå®éªŒ, æœ€å¤§å¹¶å‘æ•°: {max_workers}")
        print("=" * 60)
        
        self.start_time = time.time()
        
        # å¯åŠ¨èµ„æºç›‘æ§çº¿ç¨‹
        monitor_thread = threading.Thread(target=self.monitor_system_resources, daemon=True)
        monitor_thread.start()
        
        # å¹¶è¡Œæ‰§è¡Œå®éªŒ
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_config = {executor.submit(self.run_single_experiment, config): config 
                              for config in experiments}
            
            for future in as_completed(future_to_config):
                config = future_to_config[future]
                try:
                    result = future.result()
                    self.results[config['name']] = result
                except Exception as e:
                    print(f"âŒ å®éªŒ {config['name']} å¼‚å¸¸: {str(e)}")
                    self.results[config['name']] = {
                        'name': config['name'],
                        'return_code': -1,
                        'duration': 0,
                        'success': False,
                        'error': str(e)
                    }
        
        total_time = time.time() - self.start_time
        self.generate_summary_report(total_time)
    
    def generate_summary_report(self, total_time):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ å®éªŒæ€»ç»“æŠ¥å‘Š")
        print("=" * 60)
        
        successful = sum(1 for r in self.results.values() if r['success'])
        failed = len(self.results) - successful
        
        print(f"ğŸ“Š æ€»ä½“ç»“æœ: {successful}/{len(self.results)} ä¸ªå®éªŒæˆåŠŸ")
        print(f"â±ï¸ æ€»è€—æ—¶: {total_time/3600:.2f} å°æ—¶")
        print(f"ğŸ’» å¹³å‡æ¯ä¸ªå®éªŒ: {total_time/len(self.results)/60:.1f} åˆ†é’Ÿ")
        
        print("\nğŸ“ˆ è¯¦ç»†ç»“æœ:")
        for name, result in self.results.items():
            status = "âœ…" if result['success'] else "âŒ"
            duration = result['duration'] / 60  # è½¬æ¢ä¸ºåˆ†é’Ÿ
            print(f"  {status} {name}: {duration:.1f}åˆ†é’Ÿ")
            
            if not result['success'] and 'error' in result:
                print(f"    é”™è¯¯: {result['error']}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = os.path.join(self.base_logdir, 'experiment_report.json')
        os.makedirs(self.base_logdir, exist_ok=True)
        
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'total_experiments': len(self.results),
            'successful': successful,
            'failed': failed,
            'total_time_hours': total_time / 3600,
            'results': self.results
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # ç”Ÿæˆæ¨¡å‹æ–‡ä»¶æ±‡æ€»
        self.collect_trained_models()
    
    def collect_trained_models(self):
        """æ”¶é›†è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶"""
        print("\nğŸ” æ”¶é›†è®­ç»ƒå¥½çš„æ¨¡å‹...")
        
        model_summary = []
        
        for name, result in self.results.items():
            if result['success']:
                # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
                exp_dir = None
                for p in self.processes:
                    if p['name'] == name:
                        exp_dir = p['config']['logdir']
                        break
                
                if exp_dir and os.path.exists(exp_dir):
                    model_files = list(Path(exp_dir).glob('*.pkl'))
                    if model_files:
                        model_summary.append({
                            'experiment': name,
                            'directory': exp_dir,
                            'models': [str(f) for f in model_files]
                        })
        
        if model_summary:
            print(f"ğŸ“ æ‰¾åˆ° {len(model_summary)} ä¸ªå®éªŒçš„æ¨¡å‹æ–‡ä»¶:")
            for item in model_summary:
                print(f"  ğŸ“‚ {item['experiment']}: {len(item['models'])} ä¸ªæ¨¡å‹")
                for model in item['models']:
                    print(f"    ğŸ“„ {os.path.basename(model)}")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶")
    
    def stop_all_experiments(self):
        """åœæ­¢æ‰€æœ‰æ­£åœ¨è¿è¡Œçš„å®éªŒ"""
        print("ğŸ›‘ åœæ­¢æ‰€æœ‰å®éªŒ...")
        
        for p in self.processes:
            if 'process' in p and p['process'].poll() is None:
                try:
                    p['process'].terminate()
                    print(f"ğŸ›‘ å·²åœæ­¢å®éªŒ: {p['name']}")
                except Exception as e:
                    print(f"âŒ åœæ­¢å®éªŒ {p['name']} å¤±è´¥: {str(e)}")

def create_preset_configs():
    """åˆ›å»ºé¢„è®¾é…ç½®"""
    presets = {
        'quick_test': {
            'description': 'å¿«é€Ÿæµ‹è¯• (3ä¸ªç§å­, è¾ƒå°‘è®­ç»ƒæ­¥æ•°)',
            'seeds': [1, 2, 3],
            'args': {
                'popsize': 5,
                'rollout_size': 5,
                'num_frames': 50000
            }
        },
        'standard': {
            'description': 'æ ‡å‡†å®éªŒ (5ä¸ªç§å­)',
            'seeds': [1, 2, 3, 4, 5],
            'args': {}
        },
        'comprehensive': {
            'description': 'å…¨é¢å®éªŒ (10ä¸ªç§å­)',
            'seeds': list(range(1, 11)),
            'args': {}
        },
        'custom_seeds': {
            'description': 'è‡ªå®šä¹‰ç§å­',
            'seeds': [7, 42, 123, 456, 789],
            'args': {}
        },
        'gpu_optimized': {
            'description': 'GPUä¼˜åŒ– (5ä¸ªç§å­, é€‚åˆ16Gæ˜¾å­˜, å¯ç”¨TensorBoard)',
            'seeds': [1, 2, 3, 4, 5],
            'args': {
                'popsize': 10,
                'rollout_size': 10,
                'num_frames': 1000000,
                '-use_cuda': None,
                '-use_tensorboard': None,
                '-log_weights': None
            }
        }
    }
    return presets

def main():
    parser = argparse.ArgumentParser(description='PDERL å¹¶è¡Œè®­ç»ƒè„šæœ¬')
    parser.add_argument('-env', '--environment', 
                       help='è®­ç»ƒç¯å¢ƒåç§° (å¦‚: Hopper-v2)')
    parser.add_argument('-preset', '--preset', choices=['quick_test', 'standard', 'comprehensive', 'custom_seeds', 'gpu_optimized'],
                       default='standard', help='é¢„è®¾é…ç½®')
    parser.add_argument('-seeds', '--seeds', nargs='+', type=int,
                       help='è‡ªå®šä¹‰éšæœºç§å­åˆ—è¡¨')
    parser.add_argument('-workers', '--max_workers', type=int,
                       help='æœ€å¤§å¹¶å‘æ•° (é»˜è®¤ä¸ºCPUæ ¸å¿ƒæ•°)')
    parser.add_argument('-logdir', '--base_logdir', default='parallel_experiments',
                       help='åŸºç¡€æ—¥å¿—ç›®å½•')
    parser.add_argument('--list-presets', action='store_true',
                       help='åˆ—å‡ºæ‰€æœ‰é¢„è®¾é…ç½®')
    
    # æ·»åŠ è®­ç»ƒå‚æ•°
    parser.add_argument('-popsize', '--popsize', type=int, help='ç§ç¾¤å¤§å°')
    parser.add_argument('-rollout_size', '--rollout_size', type=int, help='Rolloutå¤§å°')
    parser.add_argument('-num_frames', '--num_frames', type=int, help='è®­ç»ƒå¸§æ•°')
    parser.add_argument('-use_cuda', '--use_cuda', action='store_true', help='ä½¿ç”¨CUDA')
    
    # TensorBoardç›¸å…³å‚æ•°
    parser.add_argument('-use_tensorboard', '--use_tensorboard', action='store_true', 
                       help='ä½¿ç”¨TensorBoardè®°å½•è®­ç»ƒè¿‡ç¨‹')
    parser.add_argument('-tensorboard_dir', '--tensorboard_dir', type=str,
                       help='TensorBoardæ—¥å¿—ç›®å½• (é»˜è®¤ä¸ºå®éªŒç›®å½•ä¸‹çš„tensorboardæ–‡ä»¶å¤¹)')
    parser.add_argument('-log_weights', '--log_weights', action='store_true',
                       help='è®°å½•ç½‘ç»œæƒé‡åˆ°TensorBoard')
    parser.add_argument('-log_freq', '--log_freq', type=int, default=10,
                       help='è¯¦ç»†æŒ‡æ ‡è®°å½•é¢‘ç‡')
    
    args = parser.parse_args()
    
    # åˆ—å‡ºé¢„è®¾é…ç½®
    if args.list_presets:
        presets = create_preset_configs()
        print("ğŸ“‹ å¯ç”¨çš„é¢„è®¾é…ç½®:")
        for name, config in presets.items():
            print(f"  {name}: {config['description']}")
            print(f"    ç§å­: {config['seeds']}")
            if config['args']:
                print(f"    å‚æ•°: {config['args']}")
            print()
        return
    
    # æ£€æŸ¥å¿…éœ€å‚æ•°
    if not args.environment:
        parser.error("è®­ç»ƒæ—¶å¿…é¡»æŒ‡å®šç¯å¢ƒ (-env/--environment)")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = ParallelTrainer(args.base_logdir)
    
    try:
        # ç¡®å®šä½¿ç”¨çš„ç§å­
        if args.seeds:
            seeds = args.seeds
            print(f"ğŸ² ä½¿ç”¨è‡ªå®šä¹‰ç§å­: {seeds}")
        else:
            presets = create_preset_configs()
            preset_config = presets[args.preset]
            seeds = preset_config['seeds']
            print(f"ğŸ² ä½¿ç”¨é¢„è®¾ '{args.preset}': {preset_config['description']}")
            print(f"ğŸ² ç§å­: {seeds}")
        
        # æ„å»ºè®­ç»ƒå‚æ•°
        train_args = {}
        if args.popsize:
            train_args['popsize'] = args.popsize
        if args.rollout_size:
            train_args['rollout_size'] = args.rollout_size
        if args.num_frames:
            train_args['num_frames'] = args.num_frames
        if args.use_cuda:
            train_args['-use_cuda'] = None
        
        # TensorBoardå‚æ•°
        if args.use_tensorboard:
            train_args['-use_tensorboard'] = None
            if args.tensorboard_dir:
                train_args['-tensorboard_dir'] = args.tensorboard_dir
            if args.log_weights:
                train_args['-log_weights'] = None
            if args.log_freq != 10:  # åªæœ‰éé»˜è®¤å€¼æ‰æ·»åŠ 
                train_args['-log_freq'] = args.log_freq
        
        # å¦‚æœä½¿ç”¨é¢„è®¾ï¼Œåˆå¹¶é¢„è®¾å‚æ•°
        if not args.seeds:
            preset_args = presets[args.preset]['args']
            train_args.update(preset_args)
        
        # åˆ›å»ºå®éªŒé…ç½®
        experiments = trainer.create_experiment_config(
            args.environment, seeds, train_args
        )
        
        print(f"ğŸ¯ ç¯å¢ƒ: {args.environment}")
        print(f"ğŸ“Š å®éªŒæ•°é‡: {len(experiments)}")
        if train_args:
            print(f"âš™ï¸ è®­ç»ƒå‚æ•°: {train_args}")
        print()
        
        # ç¡®è®¤å¼€å§‹
        response = input("æ˜¯å¦å¼€å§‹å¹¶è¡Œè®­ç»ƒ? (y/n): ")
        if response.lower() != 'y':
            print("âŒ å·²å–æ¶ˆ")
            return
        
        # å¼€å§‹å¹¶è¡Œè®­ç»ƒ
        trainer.run_parallel_experiments(experiments, args.max_workers)
        
    except KeyboardInterrupt:
        print("\nâš ï¸ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢æ‰€æœ‰å®éªŒ...")
        trainer.stop_all_experiments()
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        trainer.stop_all_experiments()

if __name__ == '__main__':
    main()